# Awesome-Survey-on-Foundation-Models-for-RL-Robotics

## Paper Taxonomy
| Paper | Year | Conference/Journal | Application | Type of foundation model | The role that VLM plays in robotics/RL |
| --- | --- |
| RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback | 2024 | arxiv | classic control, rigid and articulated object manipulation | VLMs
leveraging vision language foundation models (VLMs) that are trained on diverse, general text and image corpora (e.g., GPT-4V (OpenAI, 2023), Gemini (Team et al., 2023)). | Query these models to give preferences over pairs of the agentâ€™s image observations based on the text description of the task goal, and then learn a reward function from the preference labels. |
| git diff | Show file differences that haven't been staged |
